{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e84b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e86a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9952ff",
   "metadata": {},
   "source": [
    "## We want to eliminate \"accidental\" referrals, so filter the hop teaming data so that the transaction_count is at least 50 and the average_day_wait is less than 50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af65169",
   "metadata": {},
   "source": [
    "##  Connect Hop Teaming dataset to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "03d88170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69176709c22b4d878b2e92fef87341ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db = sqlite3.connect('data/Hop_Teaming_2018.sqlite')\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('data/DocGraph_Hop_Teaming_2018.csv', chunksize = 10000)):\n",
    "    chunk.columns = [x.lower().replace(' ', '_') for x in chunk.columns]      # Clean up the column names\n",
    "    chunk = chunk[ (chunk[ 'transaction_count' ] >= 50) & (chunk[ 'average_day_wait' ] < 50)]\n",
    "    chunk.to_sql('Hop_Teaming_2018', db, if_exists = 'append', index = False)            # Append the chunk to Hop_Teaming_2018 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d571043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT COUNT(*) FROM Hop_Teaming_2018\"\n",
    "\n",
    "with sqlite3.connect('data/Hop_Teaming_2018.sqlite') as db: \n",
    "    Hop_Teaming_sqlite = pd.read_sql(query, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef9315",
   "metadata": {},
   "source": [
    "Entity from columns should be all 1, and entity to columns should be all 2\n",
    "Referral count > 50\n",
    "Avg num of days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2031346e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0  34176938"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hop_Teaming_sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01219283",
   "metadata": {},
   "source": [
    "##  Connect nppes dataset to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5c67a0b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4cfe4bad4e46e5808810b072b500d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (71,74,75,78,79,82,83,86,87,90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (67,70,71,74,75,78,79,82,83,86,87,90,91,94) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (71,74,75,78,79,82,83,86,87,90,91,94) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (79,82,83,86,87,90,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (67,70,71,74,75,78,79,82,83,86,87,90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (71,74,75,78,79,82,83,86) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (67,70,71,74,75,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (71,74,75,78,79,82,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (71,74,75,78,79,82,83,86,87,90,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (79,82,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (71,74,75,78,79,82,83,86,87,90,91,94,95,98) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (67,70,71,74,75,78,79,82,83,86,87,90,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (63,66,67,70,71,74,75,78,79,82,83,86,87,90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (67,70,71,74) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (63,66,67,70,71,74,75,78,79,82,83,86,87,90,91,94) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (63,66,67,70,71,74,75,78,79,82,83,86,87,90,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (67,70,71,74,75,78,79,82,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (71,74,75,78,79,82) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (63,66,67,70,71,74) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (63,66,67,70,71,74,75,78,79,82) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (75,78,79,82,83,86) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (75,78,79,82,83,86,87,90,91,94,95,98) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (87,90,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (75,78,79,82,83,86,87,90,91,94) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (75,78,79,82,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (67,70,71,74,75,78,79,82,83,86) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (71,74,75,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (4,79,82,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (4,67,70,71,74,75,78,79,82) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (4,79,82,83,86,87,90,91,94,95,98) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (79,82,83,86,87,90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (79,82,83,86,87,90,91,94) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,8,9,10,67,70,71,74,75,78,79,82,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (75,78,79,82,83,86,87,90,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (87,90,91,94) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (79,82,83,86,87,90,91,94,95,98) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (67,70,71,74,75,78,79,82,83,86,87,90,91,94,95,98) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (83,86,87,90,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (83,86,87,90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (95,98) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,8,9,10,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,8,10,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,8,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,10,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,8,10,87,90,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,8,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,8,10,91,94,95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,10,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,8,10,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,8,10,79,82,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (5,6,7,8,9,10,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (75,78,79,82,83,86,87,90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (4,83,86,87,90,91,94,95,98,99,102,103,106) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n",
      "/var/folders/rd/x6jdq_810v96v83xb6ym8dlc0000gn/T/ipykernel_34721/547519739.py:9: DtypeWarning: Columns (95,98,99,102) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv',\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "types = defaultdict(None, {'Provider Business Practice Location Address Postal Code':str}) #default is a special kind of dictionary,\n",
    "                                                    #None tells read_csv to keep the types of other column types \n",
    "                                                    #but for every other column, use None\n",
    "\n",
    "\n",
    "db = sqlite3.connect('data/Hop_Teaming_2018.sqlite')\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('data/npidata_pfile_20050523-20230212.csv', \n",
    "                              dtype = types,\n",
    "                              usecols = ['NPI','Entity Type Code',\n",
    "                                         'Provider Organization Name (Legal Business Name)',\n",
    "                                         'Provider Last Name (Legal Name)',\n",
    "                                         'Provider First Name',\n",
    "                                         'Provider Middle Name',\n",
    "                                         'Provider Name Prefix Text',\n",
    "                                         'Provider Name Suffix Text',\n",
    "                                         'Provider Credential Text',\n",
    "                                         'Provider First Line Business Practice Location Address',\n",
    "                                         'Provider Second Line Business Practice Location Address',\n",
    "                                         'Provider Business Practice Location Address City Name',\n",
    "                                         'Provider Business Practice Location Address State Name',\n",
    "                                         'Provider Business Practice Location Address Postal Code',\n",
    "                                         'Healthcare Provider Taxonomy Code_1',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_1',\n",
    "                                         'Healthcare Provider Taxonomy Code_2',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_2',\n",
    "                                         'Healthcare Provider Taxonomy Code_3',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_3',\n",
    "                                         'Healthcare Provider Taxonomy Code_4',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_4',\n",
    "                                         'Healthcare Provider Taxonomy Code_5',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_5',\n",
    "                                         'Healthcare Provider Taxonomy Code_6',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_6',\n",
    "                                         'Healthcare Provider Taxonomy Code_7',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_7',\n",
    "                                         'Healthcare Provider Taxonomy Code_8',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_8',\n",
    "                                         'Healthcare Provider Taxonomy Code_9',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_9',\n",
    "                                         'Healthcare Provider Taxonomy Code_10',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_10',\n",
    "                                         'Healthcare Provider Taxonomy Code_11',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_11',\n",
    "                                         'Healthcare Provider Taxonomy Code_12',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_12',\n",
    "                                         'Healthcare Provider Taxonomy Code_13',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_13',\n",
    "                                         'Healthcare Provider Taxonomy Code_14',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_14',\n",
    "                                         'Healthcare Provider Taxonomy Code_15',\n",
    "                                         'Healthcare Provider Primary Taxonomy Switch_15',],\n",
    "                              chunksize = 10000)):\n",
    "  \n",
    "    chunk.columns = [x.lower().replace(' ', '_') for x in chunk.columns]      # Clean up the column names\n",
    "    chunk[ 'primary_taxonomy' ] = \"\"\n",
    "    for index, row in chunk.iterrows():         #code below create a list of taxonomy values IF each row has more than one 'Y'\n",
    "        chunk.loc[index, 'primary_taxonomy'] = ([ row[f'healthcare_provider_taxonomy_code_{n}'] for n in range(1,16) \\\n",
    "            if row[ f'healthcare_provider_primary_taxonomy_switch_{n}' ] == 'Y' ] \\\n",
    "                    +[row[f'healthcare_provider_taxonomy_code_1']])[0] #some rows has no switch = 'Y', \n",
    "                                                                            #which results in an empty list\n",
    "        if isinstance(row['provider_business_practice_location_address_postal_code'], str):\n",
    "            chunk.loc[index, 'provider_business_practice_location_address_postal_code'] = \\\n",
    "                row['provider_business_practice_location_address_postal_code'][0:5]   # take first 5 characters from the left\n",
    "        else: \n",
    "            chunk.loc[index, 'provider_business_practice_location_address_postal_code'] = \"\"\n",
    "      \n",
    "            \n",
    "    chunk.drop( columns=[ f'healthcare_provider_taxonomy_code_{n}' for n in range(1,16) ], inplace = True )\n",
    "    chunk.drop( columns=[ f'healthcare_provider_primary_taxonomy_switch_{n}' for n in range(1,16) ], inplace = True )\n",
    "    chunk = chunk[ ~ chunk['primary_taxonomy'].isnull() ]\n",
    "    chunk.to_sql('nppes', db, if_exists = 'append', index = False) \n",
    "    #print(chunk)\n",
    "    #break\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c20cc",
   "metadata": {},
   "source": [
    "Drop table\n",
    "DROP TABLE nppes;\n",
    "\n",
    "Rename table\n",
    "ALTER TABLE nppes1 RENAME TO nppes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3a8d1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM nppes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1b2f2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(npi)\n",
    "FROM nppes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "197c1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM nppes \n",
    "WHERE LENGTH(provider_business_practice_location_address_postal_code) <> 5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "0efabae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('data/Hop_Teaming_2018.sqlite') as db: \n",
    "    nppes_sqlite = pd.read_sql(query, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "87fe2938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7417731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0   7417731"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nppes_sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f54f7",
   "metadata": {},
   "source": [
    "##  Connect Taxonomy dataset to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1dc8b843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751d681197f5424f96279ab62cd3d9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db = sqlite3.connect('data/Hop_Teaming_2018.sqlite')\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('data/nucc_taxonomy_230.csv', encoding = 'unicode_escape', chunksize = 10000)):\n",
    "    chunk.columns = [x.lower().replace(' ', '_') for x in chunk.columns]      # Clean up the column names\n",
    "    chunk.to_sql('taxonomy', db, if_exists = 'append', index = False)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "95084b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM taxonomy LIMIT 5\"\n",
    "\n",
    "with sqlite3.connect('data/Hop_Teaming_2018.sqlite') as db: \n",
    "    taxonomy_sqlite = pd.read_sql(query, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a09ffb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>grouping</th>\n",
       "      <th>classification</th>\n",
       "      <th>specialization</th>\n",
       "      <th>definition</th>\n",
       "      <th>notes</th>\n",
       "      <th>display_name</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193200000X</td>\n",
       "      <td>Group</td>\n",
       "      <td>Multi-Specialty</td>\n",
       "      <td>None</td>\n",
       "      <td>A business group of one or more individual pra...</td>\n",
       "      <td>[7/1/2003: new]</td>\n",
       "      <td>Multi-Specialty Group</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193400000X</td>\n",
       "      <td>Group</td>\n",
       "      <td>Single Specialty</td>\n",
       "      <td>None</td>\n",
       "      <td>A business group of one or more individual pra...</td>\n",
       "      <td>[7/1/2003: new]</td>\n",
       "      <td>Single Specialty Group</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207K00000X</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians</td>\n",
       "      <td>Allergy &amp; Immunology</td>\n",
       "      <td>None</td>\n",
       "      <td>An allergist-immunologist is trained in evalua...</td>\n",
       "      <td>Source: American Board of Medical Specialties,...</td>\n",
       "      <td>Allergy &amp; Immunology Physician</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207KA0200X</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians</td>\n",
       "      <td>Allergy &amp; Immunology</td>\n",
       "      <td>Allergy</td>\n",
       "      <td>A physician who specializes in the diagnosis, ...</td>\n",
       "      <td>Source: National Uniform Claim Committee</td>\n",
       "      <td>Allergy Physician</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207KI0005X</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians</td>\n",
       "      <td>Allergy &amp; Immunology</td>\n",
       "      <td>Clinical &amp; Laboratory Immunology</td>\n",
       "      <td>An allergy and immunology physician who specia...</td>\n",
       "      <td>Source: National Uniform Claim Committee, 2022...</td>\n",
       "      <td>Clinical &amp; Laboratory Immunology (Allergy &amp; Im...</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         code                             grouping        classification  \\\n",
       "0  193200000X                                Group       Multi-Specialty   \n",
       "1  193400000X                                Group      Single Specialty   \n",
       "2  207K00000X  Allopathic & Osteopathic Physicians  Allergy & Immunology   \n",
       "3  207KA0200X  Allopathic & Osteopathic Physicians  Allergy & Immunology   \n",
       "4  207KI0005X  Allopathic & Osteopathic Physicians  Allergy & Immunology   \n",
       "\n",
       "                     specialization  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                           Allergy   \n",
       "4  Clinical & Laboratory Immunology   \n",
       "\n",
       "                                          definition  \\\n",
       "0  A business group of one or more individual pra...   \n",
       "1  A business group of one or more individual pra...   \n",
       "2  An allergist-immunologist is trained in evalua...   \n",
       "3  A physician who specializes in the diagnosis, ...   \n",
       "4  An allergy and immunology physician who specia...   \n",
       "\n",
       "                                               notes  \\\n",
       "0                                    [7/1/2003: new]   \n",
       "1                                    [7/1/2003: new]   \n",
       "2  Source: American Board of Medical Specialties,...   \n",
       "3           Source: National Uniform Claim Committee   \n",
       "4  Source: National Uniform Claim Committee, 2022...   \n",
       "\n",
       "                                        display_name     section  \n",
       "0                              Multi-Specialty Group  Individual  \n",
       "1                             Single Specialty Group  Individual  \n",
       "2                     Allergy & Immunology Physician  Individual  \n",
       "3                                  Allergy Physician  Individual  \n",
       "4  Clinical & Laboratory Immunology (Allergy & Im...  Individual  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy_sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce05496",
   "metadata": {},
   "source": [
    "##  Connect ZIP CBSA dataset to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d75f11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('data/Hop_Teaming_2018.sqlite')\n",
    "\n",
    "zip_cbsa = pd.read_excel('data/ZIP_CBSA_122021.xlsx', index_col = None, header = 0, dtype={'zip': object})\n",
    "\n",
    "# add table to database\n",
    "zip_cbsa.to_sql('zip_cbsa', db, if_exists = 'append', index = False)\n",
    "\n",
    "#create index\n",
    "db.execute('CREATE INDEX zip ON zip_cbsa(zip)')\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "14e33366",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM zip_cbsa LIMIT 5\"\n",
    "\n",
    "with sqlite3.connect('data/Hop_Teaming_2018.sqlite') as db: \n",
    "    zip_cbsa_sqlite = pd.read_sql(query, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7eb3c0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>cbsa</th>\n",
       "      <th>usps_zip_pref_city</th>\n",
       "      <th>usps_zip_pref_state</th>\n",
       "      <th>res_ratio</th>\n",
       "      <th>bus_ratio</th>\n",
       "      <th>oth_ratio</th>\n",
       "      <th>tot_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00683</td>\n",
       "      <td>41900</td>\n",
       "      <td>SAN GERMAN</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00683</td>\n",
       "      <td>32420</td>\n",
       "      <td>SAN GERMAN</td>\n",
       "      <td>PR</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00923</td>\n",
       "      <td>41980</td>\n",
       "      <td>SAN JUAN</td>\n",
       "      <td>PR</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01010</td>\n",
       "      <td>44140</td>\n",
       "      <td>BRIMFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>0.976896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01010</td>\n",
       "      <td>49340</td>\n",
       "      <td>BRIMFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>0.023104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     zip   cbsa usps_zip_pref_city usps_zip_pref_state  res_ratio  bus_ratio  \\\n",
       "0  00683  41900         SAN GERMAN                  PR   0.999842        1.0   \n",
       "1  00683  32420         SAN GERMAN                  PR   0.000158        0.0   \n",
       "2  00923  41980           SAN JUAN                  PR   1.000000        1.0   \n",
       "3  01010  44140          BRIMFIELD                  MA   0.976896        1.0   \n",
       "4  01010  49340          BRIMFIELD                  MA   0.023104        0.0   \n",
       "\n",
       "   oth_ratio  tot_ratio  \n",
       "0        1.0   0.999855  \n",
       "1        0.0   0.000145  \n",
       "2        1.0   1.000000  \n",
       "3        1.0   0.977816  \n",
       "4        0.0   0.022184  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_cbsa_sqlite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
