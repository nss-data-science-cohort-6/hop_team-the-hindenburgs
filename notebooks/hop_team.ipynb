{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64aad33dd5754046ab27fb6a12efe9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\garre\\Documents\\NSS_Projects\\hop_team-the-hindenburgs\\notebooks\\hop_team.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/garre/Documents/NSS_Projects/hop_team-the-hindenburgs/notebooks/hop_team.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m chunk\u001b[39m.\u001b[39mloc[(chunk[\u001b[39m'\u001b[39m\u001b[39mtransaction_count\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m50\u001b[39m) \u001b[39m&\u001b[39m (chunk[\u001b[39m'\u001b[39m\u001b[39maverage_day_wait\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m50\u001b[39m)] \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/garre/Documents/NSS_Projects/hop_team-the-hindenburgs/notebooks/hop_team.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Append the chunk to a calls table\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/garre/Documents/NSS_Projects/hop_team-the-hindenburgs/notebooks/hop_team.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m chunk\u001b[39m.\u001b[39;49mto_sql(\u001b[39m'\u001b[39;49m\u001b[39mhop_teaming\u001b[39;49m\u001b[39m'\u001b[39;49m, db, if_exists \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m'\u001b[39;49m, index \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\garre\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2951\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2794\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2795\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2796\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2947\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   2948\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[0;32m   2949\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[1;32m-> 2951\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m   2952\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2953\u001b[0m     name,\n\u001b[0;32m   2954\u001b[0m     con,\n\u001b[0;32m   2955\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   2956\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   2957\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   2958\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   2959\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   2960\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2961\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   2962\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\garre\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:697\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m     )\n\u001b[1;32m--> 697\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mto_sql(\n\u001b[0;32m    698\u001b[0m     frame,\n\u001b[0;32m    699\u001b[0m     name,\n\u001b[0;32m    700\u001b[0m     if_exists\u001b[39m=\u001b[39mif_exists,\n\u001b[0;32m    701\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m    702\u001b[0m     index_label\u001b[39m=\u001b[39mindex_label,\n\u001b[0;32m    703\u001b[0m     schema\u001b[39m=\u001b[39mschema,\n\u001b[0;32m    704\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m    705\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    706\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    707\u001b[0m     engine\u001b[39m=\u001b[39mengine,\n\u001b[0;32m    708\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m    709\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\garre\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2190\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, **kwargs)\u001b[0m\n\u001b[0;32m   2180\u001b[0m table \u001b[39m=\u001b[39m SQLiteTable(\n\u001b[0;32m   2181\u001b[0m     name,\n\u001b[0;32m   2182\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2187\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   2188\u001b[0m )\n\u001b[0;32m   2189\u001b[0m table\u001b[39m.\u001b[39mcreate()\n\u001b[1;32m-> 2190\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49minsert(chunksize, method)\n",
      "File \u001b[1;32mc:\\Users\\garre\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:954\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m    952\u001b[0m             total_inserted \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    953\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m             total_inserted \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m num_inserted\n\u001b[0;32m    955\u001b[0m \u001b[39mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32mc:\\Users\\garre\\anaconda3\\lib\\contextlib.py:126\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    127\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\garre\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2010\u001b[0m, in \u001b[0;36mSQLiteDatabase.run_transaction\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2008\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2009\u001b[0m     \u001b[39myield\u001b[39;00m cur\n\u001b[1;32m-> 2010\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon\u001b[39m.\u001b[39;49mcommit()\n\u001b[0;32m   2011\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   2012\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon\u001b[39m.\u001b[39mrollback()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('../data/DocGraph_Hop_Teaming_2018.csv', chunksize = 10000)):\n",
    "    # filter the required conditions (trying to eliminate accidental referrals)\n",
    "    chunk.loc[(chunk['transaction_count'] >= 50) & (chunk['average_day_wait'] < 50)] \n",
    "    # Append the chunk to a calls table\n",
    "    chunk.to_sql('hop_teaming', db, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute('CREATE INDEX from_to_npi ON hop_teaming(from_npi, to_npi)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = pd.read_csv('../data/npidata_pfile_20050523-20230212.csv', chunksize = 10000)\n",
    "test_chunk = next(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chunk.loc[(test_chunk['Healthcare Provider Primary Taxonomy Switch_1'] != 'Y') & (test_chunk['Healthcare Provider Primary Taxonomy Switch_1'] != 'N')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,16):\n",
    "    print(test_chunk.loc[test_chunk[f'Healthcare Provider Primary Taxonomy Switch_{i}'] == 'Y', f'Healthcare Provider Taxonomy Code_{i}'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxonomy(col):\n",
    "    for i in range(1, 16):\n",
    "        taxonomy_switch = f'Healthcare Provider Primary Taxonomy Switch_{i}'\n",
    "        taxonomy_value = f'Healthcare Provider Taxonomy Code_{i}'\n",
    "        if col.get(taxonomy_switch) == 'Y':\n",
    "            return col.get(taxonomy_value)\n",
    "    return 'no primary taxonomy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture [--no-stderr]\n",
    "# the capture above is here so that it doesn't show warnings about columns types and so that I avoid manually setting dozens of columns dtypes!\n",
    "\n",
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "for chunk in tqdm(pd.read_csv('../data/npidata_pfile_20050523-20230212.csv', chunksize = 10000, dtype={'Provider Business Practice Location Address Postal Code': object})):\n",
    "\n",
    "    # first extract the primary taxonomy\n",
    "    chunk['Primary Taxonomy'] = chunk.apply(lambda col: find_taxonomy(col), axis=1)\n",
    "\n",
    "    # Take only first 5 digits from postal code column\n",
    "    chunk['Provider Business Practice Location Address Postal Code'] = chunk['Provider Business Practice Location Address Postal Code'].str[:5]\n",
    "\n",
    "    # next, only keep columns we're interested in and renaming so that there are no ()\n",
    "    chunk = (\n",
    "        chunk \n",
    "        [['NPI',\n",
    "        'Entity Type Code',\n",
    "        'Provider Organization Name (Legal Business Name)',\n",
    "        'Provider Last Name (Legal Name)',\n",
    "        'Provider First Name',\n",
    "        'Provider Middle Name',\n",
    "        'Provider Name Prefix Text',\n",
    "        'Provider Name Suffix Text',\n",
    "        'Provider Credential Text',\n",
    "        'Provider First Line Business Practice Location Address',\n",
    "        'Provider Second Line Business Practice Location Address',\n",
    "        'Provider Business Practice Location Address City Name',\n",
    "        'Provider Business Practice Location Address State Name',\n",
    "        'Provider Business Practice Location Address Postal Code',\n",
    "        'Primary Taxonomy']]\n",
    "        .rename(columns={'Provider Organization Name (Legal Business Name)': 'Provider Organization Name',\n",
    "        'Provider Last Name (Legal Name)': 'Provider Last Name',\n",
    "        'Provider Name Prefix Text': 'Provider Name Prefix',\n",
    "        'Provider Name Suffix Text': 'Provider Name Suffix',\n",
    "        'Provider Business Practice Location Address City Name': 'City',\n",
    "        'Provider Business Practice Location Address State Name': 'State',\n",
    "        'Provider Business Practice Location Address Postal Code': 'Postal Code'})\n",
    "    )\n",
    "\n",
    "    # Then clean up the column names\n",
    "    chunk.columns = [x.lower().replace(' ', '_') for x in chunk.columns]\n",
    "\n",
    "    # Finally, the chunk to a calls table\n",
    "    chunk.to_sql('npidata_pfile', db, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM npidata_pfile\n",
    "WHERE provider_business_practice_location_address_city_name = 'NASHVILLE'\n",
    "AND provider_business_practice_location_address_state_name = 'TN'\n",
    "\"\"\"\n",
    "with sqlite3.connect('../data/hop_teaming_database.sqlite') as db: \n",
    "    npidata_nashville = pd.read_sql_query(query, db)\n",
    "npidata_nashville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute('CREATE INDEX npi ON npidata_pfile(npi)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "nucc_taxonomy = pd.read_csv('../data/nucc_taxonomy_230.csv', encoding = 'unicode_escape')\n",
    "\n",
    "# lowercase column names and replace spaces\n",
    "nucc_taxonomy.columns = [x.lower().replace(' ', '_') for x in nucc_taxonomy.columns]\n",
    "\n",
    "# add table to database\n",
    "nucc_taxonomy.to_sql('nucc_taxonomy', db, if_exists = 'append', index = False)\n",
    "\n",
    "#create index\n",
    "db.execute('CREATE INDEX code ON nucc_taxonomy(code)')\n",
    "\n",
    "db.close()\n",
    "\n",
    "nucc_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('../data/hop_teaming_database.sqlite')\n",
    "\n",
    "zip_cbsa = pd.read_excel('../data/ZIP_CBSA_122021.xlsx', index_col = None, header = 0, dtype={'zip': object})\n",
    "\n",
    "# add table to database\n",
    "zip_cbsa.to_sql('zip_cbsa', db, if_exists = 'append', index = False)\n",
    "\n",
    "#create index\n",
    "db.execute('CREATE INDEX zip ON zip_cbsa(zip)')\n",
    "\n",
    "db.close()\n",
    "\n",
    "zip_cbsa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69d1a9810791efba60ce1ea10d959bc27178a9f5611c0b5d3e3e72cf5155612b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
